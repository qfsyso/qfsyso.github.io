<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>AI on MLOG</title><link>https://qfsyso.github.io/tags/ai/</link><description>Recent content in AI on MLOG</description><generator>Hugo -- 0.126.3</generator><language>zh-CN</language><lastBuildDate>Sun, 21 Sep 2025 23:20:30 +0800</lastBuildDate><atom:link href="https://qfsyso.github.io/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>Cangjie AI Bot</title><link>https://qfsyso.github.io/posts/cangjie-ai-bot/</link><pubDate>Sun, 21 Sep 2025 23:20:30 +0800</pubDate><guid>https://qfsyso.github.io/posts/cangjie-ai-bot/</guid><description>基于仓颉编程语言开发AI聊天机器人
一、仓颉环境准备 1.1 仓颉版本升级（可选） 当前案例基于仓颉1.0.0开发，需确保开发环境版本一致：
# 查看当前版本 cjc -v ​​升级方案选择：​​
​​方式一：脚本升级​​（推荐） sudo wget -P /home/developer/ https://dtse-mirrors.obs.cn-north-4.myhuaweicloud.com/case/0051/cangjie1.0.0.sh \ &amp;amp;&amp;amp; sudo chmod +x /home/developer/cangjie1.0.0.sh \ &amp;amp;&amp;amp; source /home/developer/cangjie1.0.0.sh 升级后需调整IDE配置：
删除已打开的IDE终端
设置路径：CangjieSdkPath.CJNativeBackend→ /home/developer/cangjie
新建工程时SDK路径同步修改
​​方式二：云主机重置​​ 选择西南-贵阳一区域的最新镜像重置云主机（注意备份数据）
1.2 CodeArts IDE for Cangjie特性 ​​核心功能​​：语法高亮/错误诊断/自动补全/反向调试
​​跨平台支持​​：预置云主机环境，支持Windows x64本地安装
​​调试模式​​：
​​Launch模式​​：启动调试器同时加载程序
​​Attach模式​​：附加到运行中的进程
​​反向调试​​：基于记录重放查看历史调试信息
二、智能聊天助手开发流程 2.1 创建仓颉项目 打开IDE → 新建工程 → 选择executable产物类型
修改main.cj基础代码：
package demo func println_add(a: Int64, b:Int64): Int64 { let number: Int64 = a+b println(number) return number } main(): Int64 { println(&amp;#34;hello world&amp;#34;) println_add(3,4) println(&amp;#34;hello Cangjie&amp;#34;) return 0 } 2.</description></item><item><title>Dify AI</title><link>https://qfsyso.github.io/posts/dify-ai/</link><pubDate>Fri, 19 Sep 2025 21:29:52 +0800</pubDate><guid>https://qfsyso.github.io/posts/dify-ai/</guid><description>基于 DeepSeek+Dify 构建财务报表分析模型 一、案例介绍 本案例通过实操，助力开发者深入了解如何运用 Dify 和 DeepSeek 构建财务报表分析模型，切实体验 Dify 在 AI 应用开发过程中的便捷性。
二、案例内容 （一）概述 Dify：一款面向开发者与企业的 AI 应用开发平台，致力于降低 AI 技术的使用门槛。借助可视化工作流编排以及低代码开发模式，用户无需具备深厚技术背景，就能快速完成 AI 驱动智能应用的构建、部署与管理工作。
###（二）获取模型服务
1. 领取模型 本案例中，需使用华为开发者空间登录 ModelArts Studio（MaaS）平台以获取模型服务。MaaS 平台是华为云推出的大模型即服务平台，能够一站式对业界主流开源大模型进行部署托管，同时开放大模型 API 服务，可结合业界主流 Agent 开发框架，轻松构建 AI Agent 应用。具体操作步骤如下： 在开发者空间的 Firefox 浏览器中，输入华为云网址：https://www.huaweicloud.com/，进入华为云首页。 在华为云首页右上方点击 “登录”，在弹出的对话框中输入用户名和密码完成登录。 登录成功后，在华为云首页依次选择 “产品”&amp;gt;“人工智能”&amp;gt;“AI 基础平台”&amp;gt;“ModelArts Studio 大模型及服务平台”，进入 ModelArts Studio 页面。 进入 ModelArts Studio 页面后，点击进入控制台。 进入 ModelArts Studio 控制台后，首先在左上角地域选择 “西南 - 贵阳一”，随后点击 “在线推理”&amp;gt;“免费服务”。 点击 “领取额度”，额度领取成功后需等待 2-3 分钟生效，之后点击 “调用说明”，获取模型名称以及 API 地址，本案例选择领取 DeepSeek-R1-32K。 点击 “调用说明” 后，即可获取到模型名称、API 地址。</description></item><item><title>WAV STT</title><link>https://qfsyso.github.io/posts/wav-stt/</link><pubDate>Sat, 09 Aug 2025 02:24:24 +0800</pubDate><guid>https://qfsyso.github.io/posts/wav-stt/</guid><description>WAV STT Python Flask 框架
SQLite 做存储
支持批量上传音频文件
后端调用开源 STT 库
支持音频回放和文本搜索
/app ├── app.py # Flask 后端 ├── templates/ │ └── index.html # 前端页面 ├── static/ │ └── audio/ # 上传音频存储目录（Docker 内） ├── requirements.txt # 依赖 ├── Dockerfile └── stt_utils.py # STT 相关工具函数 后端核心功能 /：首页，返回上传页面
/upload：接受多文件上传，保存音频，调用 STT 转文本，保存结果进 SQLite
/audio/：提供音频文件访问，前端可回放
/search：文本搜索接口，返回匹配记录
SQLite 数据库保存：字段 id, filename, upload_time, transcript
Docker requirements.txt
flask whisper openai-whisper Code app.py
import os import sqlite3 from datetime import datetime from flask import Flask, request, render_template, send_from_directory, jsonify import whisper app = Flask(**name**) app.</description></item><item><title>Vosk STT</title><link>https://qfsyso.github.io/posts/vosk-stt/</link><pubDate>Thu, 17 Jul 2025 21:36:01 +0800</pubDate><guid>https://qfsyso.github.io/posts/vosk-stt/</guid><description>Vosk STT 一、准备环境（Debian） sudo apt update sudo apt install -y python3 python3-pip ffmpeg pip3 install --user vosk 二、下载微型中文模型（≈ 40 MB） wget https://alphacephei.com/vosk/models/vosk-model-small-cn-0.22.zip unzip vosk-model-small-cn-0.22.zip 三、保存以下脚本为 listen.py #!/usr/bin/env python3 import sys, json, os from vosk import Model, KaldiRecognizer import wave MAP = { &amp;#34;空调&amp;#34;: 1, &amp;#34;电视&amp;#34;: 2, &amp;#34;风扇&amp;#34;: 3, &amp;#34;卧室灯&amp;#34;: 4, &amp;#34;客厅灯&amp;#34;: 5 } def wav2text(path): wf = wave.open(path, &amp;#34;rb&amp;#34;) if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getframerate() != 16000: raise ValueError(&amp;#34;音频必须是 16 kHz 16-bit 单声道 WAV&amp;#34;) model = Model(&amp;#34;vosk-model-small-cn-0.</description></item><item><title>Gemini Flash</title><link>https://qfsyso.github.io/posts/gemini-flash/</link><pubDate>Sat, 26 Apr 2025 00:44:11 +0800</pubDate><guid>https://qfsyso.github.io/posts/gemini-flash/</guid><description>免费gemini2.5 API 感谢佬友 bohe佬
lobehub https://chat-preview.lobehub.com/chat
docker lobe docker run -d -p 32100:3210 \ -e OPENAI_API_KEY=sk-GBxyVLH3pWoqFkLRC63PZhKPsVSPgLElvFtysmxPvZhZX5gi \ -e OPENAI_PROXY_URL=https://x666.me/v1 \ -e ACCESS_CODE=lobe66 \ --name lobe-chat \ lobehub/lobe-chat https://lobehub.com/zh/docs/self-hosting/platform/docker
模型设置 openai sk-xx api地址 xxx/v1 获取模型列表 检查
newapi docker run -d -p 32100:3210 \ -e OPENAI_API_KEY=sk-xxx \ -e OPENAI_PROXY_URL=https://xxx.me/v1 \ -e ACCESS_CODE=lobe66 \ --name lobe-chat \ lobehub/lobe-chat #or docker run --name new-api -d --restart always \ -p 3000:3000 \ -e TZ=Asia/Shanghai \ -v /your/data/path:/data \ calciumion/new-api:latest https://docs.</description></item><item><title>AI Prompt</title><link>https://qfsyso.github.io/posts/ai-prompt/</link><pubDate>Tue, 25 Mar 2025 21:47:55 +0800</pubDate><guid>https://qfsyso.github.io/posts/ai-prompt/</guid><description>Ghibli Transform this image into a Studio Ghibli style .
3D cutie style { &amp;#34;art_style_profile&amp;#34;:{ &amp;#34;style_name&amp;#34;:&amp;#34;Minimalist 3D Illustration&amp;#34;, &amp;#34;visual_elements&amp;#34;:{ &amp;#34;shape_language&amp;#34;:&amp;#34;Soft, rounded, chunky geometry with simplified contours and no sharp edges. Emphasis on friendly, tactile forms.&amp;#34;, &amp;#34;colors&amp;#34;:{ &amp;#34;primary_palette&amp;#34;:&amp;#34;Material-based natural tones (e.g., metallic silver, wooden brown, sky blue, ceramic white). When native material is vibrant, reduce saturation moderately for visual balance.&amp;#34;, &amp;#34;accent_colors&amp;#34;:&amp;#34;Used sparingly to highlight functional or interactive parts (e.g., buttons, handles, lids) — often in warm tones like orange, amber, or rust red.</description></item><item><title>AI TTS pyVideoTrans</title><link>https://qfsyso.github.io/posts/ai-tts-pyvideotrans/</link><pubDate>Sun, 16 Mar 2025 21:53:40 +0000</pubDate><guid>https://qfsyso.github.io/posts/ai-tts-pyvideotrans/</guid><description>pyVideoTrans开源视频翻译 Translate the video from one language to another and add dubbing. 将视频从一种语言翻译为另一种语言，同时支持语音识别转录、语音合成、字幕翻译。
百度网盘下载地址: https://pan.baidu.com/s/1AFcVVL9n5TfpgiQPfOMPiw?pwd=817i GitHub地址: https://github.com/jianchang512/pyvideotrans/releases/download/v3.64/win-PatchUpdate-3.65.7z
1.选择需要转译的视频 2.选择翻译渠道 选择免费的翻译渠道即可
也可以选择部署好的模型 如 ：本地qwen:7b模型 或 ds
3.选择配音渠道 如 印度语短视频转译 则选择印度语
这里选择 Elevenlabs.io的API 选择后要在顶部菜单输入API的key
TTS设置 -&amp;gt; ElevenLabs.io 输入 key 注册有送免费的额度 https://elevenlabs.io/ 年付便宜2两个月
选择音色，可以试听 选择嵌入字幕 软字幕（双语） 保留背景音
4.选择 语音识别 语音识别模型 从 tiny 到 base -&amp;gt;small -&amp;gt; medium -&amp;gt; large-v3 模型，识别效果越来越好，但模型体积越来越大，识别速度越来越慢，需要更多CPU/内存/GPU资源。默认使用tiny模型，如果想要更好的效果，请使用更大模型 .en 后缀模型和 distil 开头的模型只用于识别英文发音视频
根据需要选择
5.点击 开始 处理视频 6.调整 音色 根据原视频男女声调整音色 ，男声选择男的音色 音色</description></item><item><title>llama-3.3-70b-versatile</title><link>https://qfsyso.github.io/posts/llama-3.3-70b-versatile/</link><pubDate>Tue, 10 Dec 2024 22:32:02 +0000</pubDate><guid>https://qfsyso.github.io/posts/llama-3.3-70b-versatile/</guid><description>llama-3.3-70b-versatile Groq API 免费使用教程 第一步：获取 API 访问 https://console.groq.com/ 完成注册并申请 API -&amp;gt; googlemail 保存获得的 API 密钥 第二步：配置 NextChat 打开 https://app.nextchat.dev/ https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web 在左侧设置中填入： 设置-&amp;gt;模型服务商-&amp;gt;Google 设置-&amp;gt;自定义接口
模型(model) llama-3.3-70b-versatile 接口地址：https://api.groq.com/openai/ API Key：填入之前获取的密钥 自定义模型：llama-3.3-70b-versatile 主要优势 响应速度：200 Token/秒 性能表现：接近 GPT-4.0 水平 完全免费使用 使用限制 每分钟限额：6000 Token 每日 API 调用：14000 次 足够普通用户日常使用 gsk_U2MI0vooKS4JyCtmNMLHWGdyxxxfqo
提问：你是什么大模型 回答： 我是人工智能模型，特别是一种大型语言模型。我的主要功能是理解和生成类似人类的文本。我的训练数据包括了大量的文本信息，这使我能够学习语言的模式和结构，并根据这个学习生成类似人类的回答。 我的能力包括但不限于： 回答问题：我可以根据我的训练数据回答广泛的题目，从科学和历史到娱乐和文化。 生成文本：我可以根据给定的提示或主题生成文本，包括文章、故事、诗歌等。 翻译：我可以进行语言之间的翻译，例如从英语翻译到西班牙语、法语、德语等。 摘要：我可以将长篇文本摘要为简短的摘要，帮助用户快速理解主要内容。 对话：我可以与用户进行对话，回答问题，提供信息，甚至参与辩论。 我的优势在于能够快速处理和生成大量信息，但是我的能力也受到训练数据的限制。因此，我可能无法总是提供完全准确或最新的信息。然而，我会尽力提供最好的答案和帮助。</description></item><item><title>stable diffusion</title><link>https://qfsyso.github.io/posts/stable-diffusion/</link><pubDate>Tue, 13 Aug 2024 21:22:29 +0000</pubDate><guid>https://qfsyso.github.io/posts/stable-diffusion/</guid><description>背景知识 部署Stable Diffusion，内置模型库+常用插件+ControlNet。
这是一项接近零基础的教程，其中并不会包含复杂的概念或者深奥的算法。换句话说，只要你稍有计算机基础，了解如何敲入命令，知道怎么使用浏览器打开网页，您就能很轻松的完成这个实验。
AI生成内容的形式相当丰富，除了文字外，还可以进行绘画、作曲、演唱、编剧、设计等。最近热度非常高的Text to Image就是AI加持下非常时髦的一种图片创造方式。看看下面这些图片，你一定很难想象它们都是AI生成的吧。
许多人可能觉得，使用AIGC有很高的门槛，普通人是很难入门的。其实不然，随着AI技术的快速发展以及众多开源项目的诞生，我们每个人都可以很轻松且廉价的使用到AIGC。谁能想到，在2018 年，人工智能生成的画作在佳士得拍卖价还高达43.25万美元，而时隔才数年，让AI为我们创作绘画已经成了人人触手可及的事情。
在这些开源项目中，Stable Diffusion无疑是优秀生之一。Stable Diffusion是一种扩散模型（Diffusion Model）的变体，称为“潜在扩散模型”（Latent Diffusion Model），由CompVis、Stability AI和LAION的研究人员和工程师创建。
它使用来自LAION-5B数据库子集的图像进行训练。使用这个模型，可以生成包括人脸在内的任何图像，因为有开源的预训练模型，所以我们也可以在自己的机器上运行它。Stable Diffusion能够根据我们提供的一些提示词以及可以调整的部分参数，通过模型计算生成一张不错的图片。
函数计算FC
函数计算（Function Compute）是一个事件驱动的全托管 Serverless 计算服务，您无需管理服务器等基础设施，只需编写代码并上传，函数计算会为您准备好计算资源，并以弹性、可靠的方式运行代码。
SD1.5 动漫风格 真人风格 轻量版 TensorRT 艺术字
提示词就是生成图片的依据，既可以是描述需要生成内容的词，例如girl, sunset, forest等； 也可以是用于是描述图像属性的词，例如best quality, beautiful, masterpiece等。我们甚至可以通过提示词选择图片生成的视角、光线、画风；人物的姿势、着装、表情、背景的内容等。
建议加上画风描述词，让您的图片更加美观，如：Cyberpunk（赛博朋克），shinkai makoto（新海诚），Ghibli Studio（吉卜力），Paul Gauguin（梵高）等等
SD提示词 qwen 你是一个优秀的导演和Stable Difusion专家。接下来我们要共同完成一部电视剧的AI创作，请你根据我给你的场景，尽可能详细地描述场景的画面，并给出制作这个场累的Stable Difusion 英语提示词，所有提示词中都要加上“画面比例16:9,超写实，高质量，&amp;ldquo;的英语，场景描述不少于200字，提示词不少于30个单词。如果你明白了，请回复“明白&amp;rdquo;，然后我将开始发给你场景。场景一:一个12岁的少年百里东君在一棵桃花树上躺着闭目养神，手上拿着一个白玉酒杯，穿着浅蓝色的长袍，带一点点花纹样式，腰间佩着长剑，阳光透过树叶酒在他的脸上，远，落雪飞，桃花盛开，显示小河，远处的凉亭、茅屋、草坪。
prompt: Prompt for Stable Diffusion: &amp;ldquo;Scene ratio 16:9, hyper-realistic, high-quality. A 12-year-old boy in ancient Chinese clothing, wearing a light blue robe with intricate patterns, lying on a branch of a peach blossom tree.</description></item><item><title>ollama gpt qwen gemma2 deepseek loacl AI</title><link>https://qfsyso.github.io/posts/ollama-gpt-qwen-gemma2-deepseek-loacl-ai/</link><pubDate>Fri, 26 Jul 2024 23:33:08 +0000</pubDate><guid>https://qfsyso.github.io/posts/ollama-gpt-qwen-gemma2-deepseek-loacl-ai/</guid><description>ollama https://ollama.com/ ollama
https://ollama.com/library models
ollama run qwen2 send a message ollama run gemma2 https://github.com/open-webui/open-webui webui
docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main N卡 gpu
docker run -d -p 3000:8080 --gpus all --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:cuda http://localhost:3000/
deepseek https://ollama.com/library/deepseek-coder-v2 deepseek-coder-v2 ~~ codeqwen sqlcoder
curl -X POST http://localhost:11434/api/generate -d &amp;#39;{ &amp;#34;model&amp;#34;: &amp;#34;llama2-chinese:7b-chat-q4_0&amp;#34;, &amp;#34;prompt&amp;#34;:&amp;#34;为什么天空是蓝色的&amp;#34; }&amp;#39; https://docs.openwebui.com/
Open WebUI Open WebUI https://docs.openwebui.com/ 安装默认配置</description></item></channel></rss>
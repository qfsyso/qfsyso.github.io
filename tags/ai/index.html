<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>AI | MLOG</title>
<meta name=keywords content><meta name=description content="A simple blog "><meta name=author content="dwd"><link rel=canonical href=https://qfsyso.github.io/tags/ai/><link crossorigin=anonymous href=/assets/css/stylesheet.f49d66caae9ea0fd43f21f29e71a8d3e284517ed770f2aa86fa012953ad3c9ef.css integrity="sha256-9J1myq6eoP1D8h8p5xqNPihFF+13Dyqob6ASlTrTye8=" rel="preload stylesheet" as=style><link rel=icon href=https://qfsyso.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://qfsyso.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://qfsyso.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://qfsyso.github.io/apple-touch-icon.png><link rel=mask-icon href=https://qfsyso.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://qfsyso.github.io/tags/ai/index.xml><link rel=alternate hreflang=en href=https://qfsyso.github.io/tags/ai/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://qfsyso.github.io/tags/ai/"><meta property="og:site_name" content="MLOG"><meta property="og:title" content="AI"><meta property="og:description" content="A simple blog "><meta property="og:locale" content="zh-CN"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="AI"><meta name=twitter:description content="A simple blog "></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://qfsyso.github.io/ accesskey=h title="MLOG (Alt + H)">MLOG</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://qfsyso.github.io/posts/ title=Archive><span>Archive</span></a></li><li><a href=https://qfsyso.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://qfsyso.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>AI</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Cangjie AI Bot</h2></header><div class=entry-content><p>基于仓颉编程语言开发AI聊天机器人
一、仓颉环境准备 1.1 仓颉版本升级（可选） 当前案例基于仓颉1.0.0开发，需确保开发环境版本一致：
# 查看当前版本 cjc -v ​​升级方案选择：​​
​​方式一：脚本升级​​（推荐） sudo wget -P /home/developer/ https://dtse-mirrors.obs.cn-north-4.myhuaweicloud.com/case/0051/cangjie1.0.0.sh \ && sudo chmod +x /home/developer/cangjie1.0.0.sh \ && source /home/developer/cangjie1.0.0.sh 升级后需调整IDE配置：
删除已打开的IDE终端
设置路径：CangjieSdkPath.CJNativeBackend→ /home/developer/cangjie
新建工程时SDK路径同步修改
​​方式二：云主机重置​​ 选择西南-贵阳一区域的最新镜像重置云主机（注意备份数据）
1.2 CodeArts IDE for Cangjie特性 ​​核心功能​​：语法高亮/错误诊断/自动补全/反向调试
​​跨平台支持​​：预置云主机环境，支持Windows x64本地安装
​​调试模式​​：
​​Launch模式​​：启动调试器同时加载程序
​​Attach模式​​：附加到运行中的进程
​​反向调试​​：基于记录重放查看历史调试信息
二、智能聊天助手开发流程 2.1 创建仓颉项目 打开IDE → 新建工程 → 选择executable产物类型
修改main.cj基础代码：
package demo func println_add(a: Int64, b:Int64): Int64 { let number: Int64 = a+b println(number) return number } main(): Int64 { println("hello world") println_add(3,4) println("hello Cangjie") return 0 } 2....</p></div><footer class=entry-footer><span title='2025-09-21 23:20:30 +0800 +0800'>September 21, 2025</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;dwd</footer><a class=entry-link aria-label="post link to Cangjie AI Bot" href=https://qfsyso.github.io/posts/cangjie-ai-bot/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Dify AI</h2></header><div class=entry-content><p>基于 DeepSeek+Dify 构建财务报表分析模型 一、案例介绍 本案例通过实操，助力开发者深入了解如何运用 Dify 和 DeepSeek 构建财务报表分析模型，切实体验 Dify 在 AI 应用开发过程中的便捷性。
二、案例内容 （一）概述 Dify：一款面向开发者与企业的 AI 应用开发平台，致力于降低 AI 技术的使用门槛。借助可视化工作流编排以及低代码开发模式，用户无需具备深厚技术背景，就能快速完成 AI 驱动智能应用的构建、部署与管理工作。
###（二）获取模型服务
1. 领取模型 本案例中，需使用华为开发者空间登录 ModelArts Studio（MaaS）平台以获取模型服务。MaaS 平台是华为云推出的大模型即服务平台，能够一站式对业界主流开源大模型进行部署托管，同时开放大模型 API 服务，可结合业界主流 Agent 开发框架，轻松构建 AI Agent 应用。具体操作步骤如下： 在开发者空间的 Firefox 浏览器中，输入华为云网址：https://www.huaweicloud.com/，进入华为云首页。 在华为云首页右上方点击 “登录”，在弹出的对话框中输入用户名和密码完成登录。 登录成功后，在华为云首页依次选择 “产品”>“人工智能”>“AI 基础平台”>“ModelArts Studio 大模型及服务平台”，进入 ModelArts Studio 页面。 进入 ModelArts Studio 页面后，点击进入控制台。 进入 ModelArts Studio 控制台后，首先在左上角地域选择 “西南 - 贵阳一”，随后点击 “在线推理”>“免费服务”。 点击 “领取额度”，额度领取成功后需等待 2-3 分钟生效，之后点击 “调用说明”，获取模型名称以及 API 地址，本案例选择领取 DeepSeek-R1-32K。 点击 “调用说明” 后，即可获取到模型名称、API 地址。...</p></div><footer class=entry-footer><span title='2025-09-19 21:29:52 +0800 +0800'>September 19, 2025</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;dwd</footer><a class=entry-link aria-label="post link to Dify AI" href=https://qfsyso.github.io/posts/dify-ai/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>WAV STT</h2></header><div class=entry-content><p>WAV STT Python Flask 框架
SQLite 做存储
支持批量上传音频文件
后端调用开源 STT 库
支持音频回放和文本搜索
/app ├── app.py # Flask 后端 ├── templates/ │ └── index.html # 前端页面 ├── static/ │ └── audio/ # 上传音频存储目录（Docker 内） ├── requirements.txt # 依赖 ├── Dockerfile └── stt_utils.py # STT 相关工具函数 后端核心功能 /：首页，返回上传页面
/upload：接受多文件上传，保存音频，调用 STT 转文本，保存结果进 SQLite
/audio/：提供音频文件访问，前端可回放
/search：文本搜索接口，返回匹配记录
SQLite 数据库保存：字段 id, filename, upload_time, transcript
Docker requirements.txt
flask whisper openai-whisper Code app.py
import os import sqlite3 from datetime import datetime from flask import Flask, request, render_template, send_from_directory, jsonify import whisper app = Flask(**name**) app....</p></div><footer class=entry-footer><span title='2025-08-09 02:24:24 +0800 +0800'>August 9, 2025</span>&nbsp;·&nbsp;9 min&nbsp;·&nbsp;dwd</footer><a class=entry-link aria-label="post link to WAV STT" href=https://qfsyso.github.io/posts/wav-stt/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Vosk STT</h2></header><div class=entry-content><p>Vosk STT 一、准备环境（Debian） sudo apt update sudo apt install -y python3 python3-pip ffmpeg pip3 install --user vosk 二、下载微型中文模型（≈ 40 MB） wget https://alphacephei.com/vosk/models/vosk-model-small-cn-0.22.zip unzip vosk-model-small-cn-0.22.zip 三、保存以下脚本为 listen.py #!/usr/bin/env python3 import sys, json, os from vosk import Model, KaldiRecognizer import wave MAP = { "空调": 1, "电视": 2, "风扇": 3, "卧室灯": 4, "客厅灯": 5 } def wav2text(path): wf = wave.open(path, "rb") if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getframerate() != 16000: raise ValueError("音频必须是 16 kHz 16-bit 单声道 WAV") model = Model("vosk-model-small-cn-0....</p></div><footer class=entry-footer><span title='2025-07-17 21:36:01 +0800 +0800'>July 17, 2025</span>&nbsp;·&nbsp;44 min&nbsp;·&nbsp;dwd</footer><a class=entry-link aria-label="post link to Vosk STT" href=https://qfsyso.github.io/posts/vosk-stt/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Gemini Flash</h2></header><div class=entry-content><p>免费gemini2.5 API 感谢佬友 bohe佬
lobehub https://chat-preview.lobehub.com/chat
docker lobe docker run -d -p 32100:3210 \ -e OPENAI_API_KEY=sk-GBxyVLH3pWoqFkLRC63PZhKPsVSPgLElvFtysmxPvZhZX5gi \ -e OPENAI_PROXY_URL=https://x666.me/v1 \ -e ACCESS_CODE=lobe66 \ --name lobe-chat \ lobehub/lobe-chat https://lobehub.com/zh/docs/self-hosting/platform/docker
模型设置 openai sk-xx api地址 xxx/v1 获取模型列表 检查
newapi docker run -d -p 32100:3210 \ -e OPENAI_API_KEY=sk-xxx \ -e OPENAI_PROXY_URL=https://xxx.me/v1 \ -e ACCESS_CODE=lobe66 \ --name lobe-chat \ lobehub/lobe-chat #or docker run --name new-api -d --restart always \ -p 3000:3000 \ -e TZ=Asia/Shanghai \ -v /your/data/path:/data \ calciumion/new-api:latest https://docs....</p></div><footer class=entry-footer><span title='2025-04-26 00:44:11 +0800 +0800'>April 26, 2025</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;dwd</footer><a class=entry-link aria-label="post link to Gemini Flash" href=https://qfsyso.github.io/posts/gemini-flash/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>AI Prompt</h2></header><div class=entry-content><p>Ghibli Transform this image into a Studio Ghibli style .
3D cutie style { "art_style_profile":{ "style_name":"Minimalist 3D Illustration", "visual_elements":{ "shape_language":"Soft, rounded, chunky geometry with simplified contours and no sharp edges. Emphasis on friendly, tactile forms.", "colors":{ "primary_palette":"Material-based natural tones (e.g., metallic silver, wooden brown, sky blue, ceramic white). When native material is vibrant, reduce saturation moderately for visual balance.", "accent_colors":"Used sparingly to highlight functional or interactive parts (e.g., buttons, handles, lids) — often in warm tones like orange, amber, or rust red....</p></div><footer class=entry-footer><span title='2025-03-25 21:47:55 +0800 +0800'>March 25, 2025</span>&nbsp;·&nbsp;12 min&nbsp;·&nbsp;dwd</footer><a class=entry-link aria-label="post link to AI Prompt" href=https://qfsyso.github.io/posts/ai-prompt/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>AI TTS pyVideoTrans</h2></header><div class=entry-content><p>pyVideoTrans开源视频翻译 Translate the video from one language to another and add dubbing. 将视频从一种语言翻译为另一种语言，同时支持语音识别转录、语音合成、字幕翻译。
百度网盘下载地址: https://pan.baidu.com/s/1AFcVVL9n5TfpgiQPfOMPiw?pwd=817i GitHub地址: https://github.com/jianchang512/pyvideotrans/releases/download/v3.64/win-PatchUpdate-3.65.7z
1.选择需要转译的视频 2.选择翻译渠道 选择免费的翻译渠道即可
也可以选择部署好的模型 如 ：本地qwen:7b模型 或 ds
3.选择配音渠道 如 印度语短视频转译 则选择印度语
这里选择 Elevenlabs.io的API 选择后要在顶部菜单输入API的key
TTS设置 -> ElevenLabs.io 输入 key 注册有送免费的额度 https://elevenlabs.io/ 年付便宜2两个月
选择音色，可以试听 选择嵌入字幕 软字幕（双语） 保留背景音
4.选择 语音识别 语音识别模型 从 tiny 到 base ->small -> medium -> large-v3 模型，识别效果越来越好，但模型体积越来越大，识别速度越来越慢，需要更多CPU/内存/GPU资源。默认使用tiny模型，如果想要更好的效果，请使用更大模型 .en 后缀模型和 distil 开头的模型只用于识别英文发音视频
根据需要选择
5.点击 开始 处理视频 6.调整 音色 根据原视频男女声调整音色 ，男声选择男的音色 音色...</p></div><footer class=entry-footer><span title='2025-03-16 21:53:40 +0000 UTC'>March 16, 2025</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;dwd</footer><a class=entry-link aria-label="post link to AI TTS pyVideoTrans" href=https://qfsyso.github.io/posts/ai-tts-pyvideotrans/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>llama-3.3-70b-versatile</h2></header><div class=entry-content><p>llama-3.3-70b-versatile Groq API 免费使用教程 第一步：获取 API 访问 https://console.groq.com/ 完成注册并申请 API -> googlemail 保存获得的 API 密钥 第二步：配置 NextChat 打开 https://app.nextchat.dev/ https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web 在左侧设置中填入： 设置->模型服务商->Google 设置->自定义接口
模型(model) llama-3.3-70b-versatile 接口地址：https://api.groq.com/openai/ API Key：填入之前获取的密钥 自定义模型：llama-3.3-70b-versatile 主要优势 响应速度：200 Token/秒 性能表现：接近 GPT-4.0 水平 完全免费使用 使用限制 每分钟限额：6000 Token 每日 API 调用：14000 次 足够普通用户日常使用 gsk_U2MI0vooKS4JyCtmNMLHWGdyxxxfqo
提问：你是什么大模型 回答： 我是人工智能模型，特别是一种大型语言模型。我的主要功能是理解和生成类似人类的文本。我的训练数据包括了大量的文本信息，这使我能够学习语言的模式和结构，并根据这个学习生成类似人类的回答。 我的能力包括但不限于： 回答问题：我可以根据我的训练数据回答广泛的题目，从科学和历史到娱乐和文化。 生成文本：我可以根据给定的提示或主题生成文本，包括文章、故事、诗歌等。 翻译：我可以进行语言之间的翻译，例如从英语翻译到西班牙语、法语、德语等。 摘要：我可以将长篇文本摘要为简短的摘要，帮助用户快速理解主要内容。 对话：我可以与用户进行对话，回答问题，提供信息，甚至参与辩论。 我的优势在于能够快速处理和生成大量信息，但是我的能力也受到训练数据的限制。因此，我可能无法总是提供完全准确或最新的信息。然而，我会尽力提供最好的答案和帮助。</p></div><footer class=entry-footer><span title='2024-12-10 22:32:02 +0000 UTC'>December 10, 2024</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;dwd</footer><a class=entry-link aria-label="post link to llama-3.3-70b-versatile" href=https://qfsyso.github.io/posts/llama-3.3-70b-versatile/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>stable diffusion</h2></header><div class=entry-content><p>背景知识 部署Stable Diffusion，内置模型库+常用插件+ControlNet。
这是一项接近零基础的教程，其中并不会包含复杂的概念或者深奥的算法。换句话说，只要你稍有计算机基础，了解如何敲入命令，知道怎么使用浏览器打开网页，您就能很轻松的完成这个实验。
AI生成内容的形式相当丰富，除了文字外，还可以进行绘画、作曲、演唱、编剧、设计等。最近热度非常高的Text to Image就是AI加持下非常时髦的一种图片创造方式。看看下面这些图片，你一定很难想象它们都是AI生成的吧。
许多人可能觉得，使用AIGC有很高的门槛，普通人是很难入门的。其实不然，随着AI技术的快速发展以及众多开源项目的诞生，我们每个人都可以很轻松且廉价的使用到AIGC。谁能想到，在2018 年，人工智能生成的画作在佳士得拍卖价还高达43.25万美元，而时隔才数年，让AI为我们创作绘画已经成了人人触手可及的事情。
在这些开源项目中，Stable Diffusion无疑是优秀生之一。Stable Diffusion是一种扩散模型（Diffusion Model）的变体，称为“潜在扩散模型”（Latent Diffusion Model），由CompVis、Stability AI和LAION的研究人员和工程师创建。
它使用来自LAION-5B数据库子集的图像进行训练。使用这个模型，可以生成包括人脸在内的任何图像，因为有开源的预训练模型，所以我们也可以在自己的机器上运行它。Stable Diffusion能够根据我们提供的一些提示词以及可以调整的部分参数，通过模型计算生成一张不错的图片。
函数计算FC
函数计算（Function Compute）是一个事件驱动的全托管 Serverless 计算服务，您无需管理服务器等基础设施，只需编写代码并上传，函数计算会为您准备好计算资源，并以弹性、可靠的方式运行代码。
SD1.5 动漫风格 真人风格 轻量版 TensorRT 艺术字
提示词就是生成图片的依据，既可以是描述需要生成内容的词，例如girl, sunset, forest等； 也可以是用于是描述图像属性的词，例如best quality, beautiful, masterpiece等。我们甚至可以通过提示词选择图片生成的视角、光线、画风；人物的姿势、着装、表情、背景的内容等。
建议加上画风描述词，让您的图片更加美观，如：Cyberpunk（赛博朋克），shinkai makoto（新海诚），Ghibli Studio（吉卜力），Paul Gauguin（梵高）等等
SD提示词 qwen 你是一个优秀的导演和Stable Difusion专家。接下来我们要共同完成一部电视剧的AI创作，请你根据我给你的场景，尽可能详细地描述场景的画面，并给出制作这个场累的Stable Difusion 英语提示词，所有提示词中都要加上“画面比例16:9,超写实，高质量，“的英语，场景描述不少于200字，提示词不少于30个单词。如果你明白了，请回复“明白”，然后我将开始发给你场景。场景一:一个12岁的少年百里东君在一棵桃花树上躺着闭目养神，手上拿着一个白玉酒杯，穿着浅蓝色的长袍，带一点点花纹样式，腰间佩着长剑，阳光透过树叶酒在他的脸上，远，落雪飞，桃花盛开，显示小河，远处的凉亭、茅屋、草坪。
prompt: Prompt for Stable Diffusion: “Scene ratio 16:9, hyper-realistic, high-quality. A 12-year-old boy in ancient Chinese clothing, wearing a light blue robe with intricate patterns, lying on a branch of a peach blossom tree....</p></div><footer class=entry-footer><span title='2024-08-13 21:22:29 +0000 UTC'>August 13, 2024</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;dwd</footer><a class=entry-link aria-label="post link to stable diffusion" href=https://qfsyso.github.io/posts/stable-diffusion/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>ollama gpt qwen gemma2 deepseek loacl AI</h2></header><div class=entry-content><p>ollama https://ollama.com/ ollama
https://ollama.com/library models
ollama run qwen2 send a message ollama run gemma2 https://github.com/open-webui/open-webui webui
docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main N卡 gpu
docker run -d -p 3000:8080 --gpus all --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:cuda http://localhost:3000/
deepseek https://ollama.com/library/deepseek-coder-v2 deepseek-coder-v2 ~~ codeqwen sqlcoder
curl -X POST http://localhost:11434/api/generate -d '{ "model": "llama2-chinese:7b-chat-q4_0", "prompt":"为什么天空是蓝色的" }' https://docs.openwebui.com/
Open WebUI Open WebUI https://docs.openwebui.com/ 安装默认配置...</p></div><footer class=entry-footer><span title='2024-07-26 23:33:08 +0000 UTC'>July 26, 2024</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;dwd</footer><a class=entry-link aria-label="post link to ollama gpt qwen gemma2 deepseek loacl AI" href=https://qfsyso.github.io/posts/ollama-gpt-qwen-gemma2-deepseek-loacl-ai/></a></article></main><footer class=footer><div class=wtime><div class=wtime2>CST<span id=beijingTime></span> GMT <span id=londonTime></span> EST <span id=newYorkTime></span> PST<span id=losAngelesTime></span></div><div class=wtime2 style=display:none>东京<span id=tokyoTime></span></div><div class=wtime2 style=display:none>欧洲-巴黎<span id=parisTime></span></div><div class=wtime2 style=display:none>UTC<span id=utcTime></span></div></div><span>&copy; 2025 <a href=https://qfsyso.github.io/>MLOG</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a>
</span><script type=text/javascript>const timeZoneOffsets={beijing:8,tokyo:9,paris:[1,2],london:[0,1],newYork:[-5,-4],losAngeles:[-8,-7]};function padZero(e){return e<10?"0"+e:e}function formatTime(e){const t=e.getFullYear(),n=padZero(e.getMonth()+1),s=padZero(e.getDate()),o=padZero(e.getHours()),i=padZero(e.getMinutes()),a=padZero(e.getSeconds());return`${t}-${n}-${s} ${o}:${i}:${a}`}function isDaylightSavingTime(e,t){const o=e.getMonth(),n=new Date(e.getFullYear(),3,8,2,0,0),s=new Date(e.getFullYear(),10,1,2,0,0);return(t==="paris"||t==="london"||t==="newYork"||t==="losAngeles")&&e>=n&&e<s}function updateTime(){const e=new Date,t=new Date(e.getUTCFullYear(),e.getUTCMonth(),e.getUTCDate(),e.getUTCHours(),e.getUTCMinutes(),e.getUTCSeconds()),n=formatTime(t);document.getElementById("utcTime").innerHTML=n;for(const n in timeZoneOffsets){const e=timeZoneOffsets[n];let s;Array.isArray(e)?s=isDaylightSavingTime(t,n)?e[1]:e[0]:s=e;const o=new Date(t.getTime()+s*60*60*1e3);document.getElementById(n+"Time").innerHTML=formatTime(o)}setTimeout(updateTime,1e3)}window.onload=function(){updateTime()};function notfound(e){var n=e.src,t=n.split("/"),s=t[t.length-1];e.src="https://47.115.223.75:8080/group1/v2/"+s+"?timestamp="+Date.now(),e.onerror=null}</script></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>